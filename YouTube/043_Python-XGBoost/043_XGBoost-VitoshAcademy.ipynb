{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c41c38b7-1f59-4293-a169-7a9f345d38a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing share (top 5):\n",
      " age                 0.020714\n",
      "monthly_spend       0.020643\n",
      "is_international    0.020500\n",
      "support_calls       0.019571\n",
      "debt_ratio          0.019429\n",
      "dtype: float64 \n",
      "\n",
      "Class share:\n",
      " churn\n",
      "0    0.598786\n",
      "1    0.401214\n",
      "Name: share, dtype: float64 \n",
      "\n",
      "Shapes -> train (8400, 7), val (2800, 7), test (2800, 7)\n",
      "Class balance in train -> neg 5029, pos 3371, scale_pos_weight 1.49\n",
      "\n",
      "Best trees (baseline): 152\n",
      "Chosen threshold t_best (validation F1): 0.446 \n",
      "\n",
      "Confusion matrix:\n",
      " [[1246  431]\n",
      " [ 195  928]]\n",
      "Precision: 0.683\n",
      "Recall   : 0.826\n",
      "ROC AUC  : 0.862\n",
      "PR  AUC  : 0.803 \n",
      "\n",
      "Top features by importance (gain):\n",
      " support_calls       42.918461\n",
      "promo_eligible       9.714828\n",
      "age                  7.615518\n",
      "is_international     5.631215\n",
      "debt_ratio           5.196256\n",
      "tenure_months        4.838071\n",
      "monthly_spend        4.002041\n",
      "dtype: float64 \n",
      "\n",
      "Best trees (constrained): 33\n",
      "PR AUC  baseline vs constrained: 0.803 vs 0.801\n",
      "ROC AUC baseline vs constrained: 0.862 vs 0.863 \n",
      "\n",
      "Saved models: easy_xgb_base.ubj, easy_xgb_cons.ubj\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix, precision_score, recall_score,\n",
    "    roc_auc_score, average_precision_score, precision_recall_curve\n",
    ")\n",
    "\n",
    "# 1) Load a tiny cusomer churn CSV called churn.csv \n",
    "df = pd.read_csv(\"churn.csv\")\n",
    "\n",
    "# 2) Do quick, safe checks - missing values and class balance.\n",
    "missing_share = df.isna().mean().sort_values(ascending=False)\n",
    "class_share = df[\"churn\"].value_counts(normalize=True).rename(\"share\")\n",
    "print(\"Missing share (top 5):\\n\", missing_share.head(5), \"\\n\")\n",
    "print(\"Class share:\\n\", class_share, \"\\n\")\n",
    "\n",
    "# 3) Split data into train, validation, test - 60-20-20.\n",
    "X = df.drop(columns=[\"churn\"]); y = df[\"churn\"]\n",
    "X_tr, X_te, y_tr, y_te = train_test_split(X, y, test_size=0.20, stratify=y, random_state=13)\n",
    "X_tr, X_va, y_tr, y_va = train_test_split(X_tr, y_tr, test_size=0.25, stratify=y_tr, random_state=13)\n",
    "neg, pos = int((y_tr==0).sum()), int((y_tr==1).sum())\n",
    "spw = neg / max(pos, 1)\n",
    "print(f\"Shapes -> train {X_tr.shape}, val {X_va.shape}, test {X_te.shape}\")\n",
    "print(f\"Class balance in train -> neg {neg}, pos {pos}, scale_pos_weight {spw:.2f}\\n\")\n",
    "\n",
    "# Wrap as DMatrix (fast internal format)\n",
    "feat_names = list(X.columns)\n",
    "dtr = xgb.DMatrix(X_tr, label=y_tr, feature_names=feat_names)\n",
    "dva = xgb.DMatrix(X_va, label=y_va, feature_names=feat_names)\n",
    "dte = xgb.DMatrix(X_te, label=y_te, feature_names=feat_names)\n",
    "\n",
    "# 4) Train XGBoost with early stopping using the Booster API.\n",
    "params = dict(\n",
    "    objective=\"binary:logistic\",\n",
    "    eval_metric=\"aucpr\",\n",
    "    tree_method=\"hist\",\n",
    "    max_depth=5,\n",
    "    eta=0.03,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    reg_lambda=1.0,\n",
    "    scale_pos_weight=spw\n",
    ")\n",
    "bst = xgb.train(params, dtr, num_boost_round=4000, evals=[(dva, \"val\")],\n",
    "                early_stopping_rounds=200, verbose_eval=False)\n",
    "print(\"Best trees (baseline):\", bst.best_iteration)\n",
    "\n",
    "# 6) Choose a practical decision treshold from validation - \"a line in the sand\".\n",
    "p_va = bst.predict(dva, iteration_range=(0, bst.best_iteration + 1))\n",
    "pre, rec, thr = precision_recall_curve(y_va, p_va)\n",
    "f1 = 2 * pre * rec / np.clip(pre + rec, 1e-9, None)\n",
    "t_best = float(thr[np.argmax(f1[:-1])])\n",
    "print(\"Chosen threshold t_best (validation F1):\", round(t_best, 3), \"\\n\")\n",
    "\n",
    "# 7) Explain results on the test set in plain terms - confusion matrix, precision, recall, ROC AUC, PR AUC\n",
    "p_te = bst.predict(dte, iteration_range=(0, bst.best_iteration + 1))\n",
    "pred = (p_te >= t_best).astype(int)\n",
    "cm = confusion_matrix(y_te, pred)\n",
    "print(\"Confusion matrix:\\n\", cm)\n",
    "print(\"Precision:\", round(precision_score(y_te, pred), 3))\n",
    "print(\"Recall   :\", round(recall_score(y_te, pred), 3))\n",
    "print(\"ROC AUC  :\", round(roc_auc_score(y_te, p_te), 3))\n",
    "print(\"PR  AUC  :\", round(average_precision_score(y_te, p_te), 3), \"\\n\")\n",
    "\n",
    "# 8) See which column mattered most\n",
    "# (a hint - if people start calling the call centre a lot, most probably there is a problem and they will quit using your service)\n",
    "imp = pd.Series(bst.get_score(importance_type=\"gain\")).sort_values(ascending=False)\n",
    "print(\"Top features by importance (gain):\\n\", imp.head(10), \"\\n\")\n",
    "\n",
    "# 9) Add two business rules with monotonic constraints\n",
    "cons = [0]*len(feat_names)\n",
    "if \"debt_ratio\" in feat_names: cons[feat_names.index(\"debt_ratio\")] = 1     # non-decreasing\n",
    "if \"tenure_months\" in feat_names: cons[feat_names.index(\"tenure_months\")] = -1  # non-increasing\n",
    "mono = \"(\" + \",\".join(map(str, cons)) + \")\"\n",
    "\n",
    "params_cons = params.copy()\n",
    "params_cons.update({\"monotone_constraints\": mono, \"max_bin\": 512})\n",
    "\n",
    "bst_cons = xgb.train(params_cons, dtr, num_boost_round=4000, evals=[(dva, \"val\")],\n",
    "                     early_stopping_rounds=200, verbose_eval=False)\n",
    "print(\"Best trees (constrained):\", bst_cons.best_iteration)\n",
    "\n",
    "# 10) Compare the quality of bst_cons and bst with a few lines.\n",
    "p_cons = bst_cons.predict(dte, iteration_range=(0, bst_cons.best_iteration + 1))\n",
    "print(\"PR AUC  baseline vs constrained:\", round(average_precision_score(y_te, p_te), 3),\n",
    "      \"vs\", round(average_precision_score(y_te, p_cons), 3))\n",
    "print(\"ROC AUC baseline vs constrained:\", round(roc_auc_score(y_te, p_te), 3),\n",
    "      \"vs\", round(roc_auc_score(y_te, p_cons), 3), \"\\n\")\n",
    "\n",
    "# 11) Save both models\n",
    "bst.save_model(\"easy_xgb_base.ubj\")\n",
    "bst_cons.save_model(\"easy_xgb_cons.ubj\")\n",
    "print(\"Saved models: easy_xgb_base.ubj, easy_xgb_cons.ubj\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f5ee52a-7195-4775-8e2b-6e6f80637aa7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.13 (conda)",
   "language": "python",
   "name": "py313"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
